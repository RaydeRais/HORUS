import os
import base64
import requests
import re
from PIL import Image
from dotenv import load_dotenv

# ==== é…ç½® ====
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
base_url = os.getenv("OPENAI_BASE_URL") or "https://api.openai-hk.com/v1"
headers = {
    "Authorization": f"Bearer {api_key}",
    "Content-Type": "application/json"
}
vision_model = os.getenv("OPENAI_MODEL_NAME") or "gpt-4-vision-preview"
text_model = "gpt-3.5-turbo-1106"
use_proxy = os.getenv("USE_PROXY", "False").lower() == "true"
proxy_url = os.getenv("PROXY_URL")
proxies = {"https": proxy_url} if use_proxy and proxy_url else None

report_dir = r"D:\DATA\outt"
file_prefix = "watch_2"   # â† æ¢æˆè‡ªå·±çš„æ–‡ä»¶å‰ç¼€ï¼Œæ¯”å¦‚"watch_2"

# ==== å›¾ç‰‡å‹ç¼©å‡½æ•° ====
def compress_image(path, max_size=(1200, 1200), jpeg_quality=80):
    try:
        with Image.open(path) as img:
            if img.size[0] > max_size[0] or img.size[1] > max_size[1]:
                img.thumbnail(max_size, Image.LANCZOS)
                img = img.convert("RGB")
                img.save(path, format="JPEG", quality=jpeg_quality)
    except Exception as e:
        print(f"âŒ å‹ç¼©å¤±è´¥ {path}ï¼š{e}")

def img_to_base64(path):
    compress_image(path)
    with open(path, "rb") as img_f:
        return base64.b64encode(img_f.read()).decode("utf-8")

# ==== ç»“æ„åŒ–æå–ï¼ˆåŒä¹‹å‰æ•ˆæœæœ€å¥½çš„ç‰ˆæœ¬ï¼‰====
def extract_key_areas(report_text, top_k=10):
    pattern = r"\[åŒºåŸŸ (\d+)\] åæ ‡: \(([\d, ]+)\)\s+æ€»åˆ†: ([\d\.]+) \| ELA: ([\d\.]+) \| Noise: ([\d\.]+) \| FFT: ([\d\.]+)"
    results = re.findall(pattern, report_text)
    if not results:
        return "æœªæ£€æµ‹åˆ°å…¸å‹ä¼ªé€ åŒºåŸŸã€‚"
    area_list = []
    for item in results:
        idx, xywh, score, ela, noise, fft = item
        area_list.append({
            "ç¼–å·": int(idx),
            "åæ ‡": xywh,
            "æ€»åˆ†": float(score),
            "ELA": float(ela),
            "Noise": float(noise),
            "FFT": float(fft),
        })
    area_list.sort(key=lambda x: -x["æ€»åˆ†"])
    top_areas = area_list[:top_k]
    summary = ""
    for a in top_areas:
        summary += f"åŒºåŸŸ{a['ç¼–å·']} | åæ ‡({a['åæ ‡']}) | æ€»åˆ†{a['æ€»åˆ†']:.2f} | ELA:{a['ELA']:.2f} | Noise:{a['Noise']:.2f} | FFT:{a['FFT']:.2f}\n"
    return summary.strip()

def gpt_summarize_key_areas(key_area_text, model=text_model):
    prompt = (
        "è¯·æ ¹æ®ä»¥ä¸‹æ£€æµ‹åŒºåŸŸæ•°æ®ï¼Œæç‚¼ä¸»è¦ä¼ªé€ é£é™©ç‚¹ã€å¼‚å¸¸æŒ‡æ ‡åŠèšé›†è¶‹åŠ¿ï¼Œ"
        "ç”¨ç®€æ´æ˜äº†çš„ä¸­æ–‡è¾“å‡ºæ€»ç»“ï¼ˆåŒ…å«ç¼–å·ã€åæ ‡ã€å¾—åˆ†ã€å¯ç–‘åŒºåŸŸåˆ†å¸ƒã€å»ºè®®ï¼‰ã€‚"
        "æŠ¥å‘Šå¦‚ä¸‹ï¼š\n" + key_area_text
    )
    payload = {
        "model": model,
        "max_tokens": 800,
        "temperature": 0.2,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åå›¾åƒå–è¯åˆ†æä¸“å®¶ï¼Œæ“…é•¿å¯ç–‘åŒºåŸŸæ€»ç»“ä¸å¼‚å¸¸è¶‹åŠ¿åˆ†æã€‚"},
            {"role": "user", "content": prompt}
        ]
    }
    try:
        resp = requests.post(
            f"{base_url}/chat/completions",
            headers=headers,
            json=payload,
            proxies=proxies,
            timeout=90
        )
        resp.raise_for_status()
        print("ğŸ“‘ æ–‡æœ¬æ‘˜è¦å®Œæˆ âœ…")
        return resp.json()["choices"][0]["message"]["content"]
    except Exception as e:
        print("âŒ æ–‡æœ¬æ‘˜è¦å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç»“æ„ä»£æ›¿ï¼š", e)
        return key_area_text

# ==== æ‰¹é‡ä¸»å¾ªç¯ ====
def process_batch_reports(report_dir, file_prefix, top_k=10):
    page = 1
    while True:
        tag = f"{file_prefix}_p{page}"
        report_path = os.path.join(report_dir, f"{tag}_report.txt")
        heatmap_path = os.path.join(report_dir, f"{tag}_heatmap.jpg")
        marked_path = os.path.join(report_dir, f"{tag}_marked.jpg")
        output_path = os.path.join(report_dir, f"{tag}_final_report.txt")

        if not os.path.exists(report_path):
            break  # æ²¡æœ‰å°±åœ

        if not os.path.exists(heatmap_path) or not os.path.exists(marked_path):
            print(f"âŒ ç¬¬{page}é¡µç¼ºå›¾ç‰‡ï¼Œè·³è¿‡")
            page += 1
            continue

        print(f"\n===== æ­£åœ¨å¤„ç†ç¬¬{page}é¡µ =====")
        with open(report_path, "r", encoding="utf-8") as f:
            report_text = f.read()

        key_area_text = extract_key_areas(report_text, top_k=top_k)
        summarized_text = gpt_summarize_key_areas(key_area_text)

        heatmap_b64 = img_to_base64(heatmap_path)
        marked_b64 = img_to_base64(marked_path)

        payload = {
            "model": vision_model,
            "max_tokens": 1200,
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€åå›¾åƒå–è¯ä¸“å®¶ï¼Œæ“…é•¿åˆ†æå›¾åƒæ¶‚æ”¹å’Œä¼ªé€ è¡Œä¸ºã€‚"
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"ä»¥ä¸‹æ˜¯ä¼ªé€ æ£€æµ‹ç¨‹åºçš„æ ¸å¿ƒæ‘˜è¦ï¼ˆæ•°å­—ç»“è®º+AIå½’çº³ï¼‰ï¼Œè¯·ç»“åˆçƒ­åŠ›å›¾å’Œæ ‡æ³¨å›¾ï¼Œç»¼åˆåˆ†æå¹¶å›ç­”ï¼š\n"
                                    f"1. æ˜¯å¦å­˜åœ¨ä¼ªé€ åŒºåŸŸï¼Ÿ\n"
                                    f"2. é«˜åˆ†æ•°åŒºåŸŸæ˜¯å¦æç¤ºé«˜åº¦é£é™©ï¼Ÿ\n"
                                    f"3. æ˜¯å¦å»ºè®®äººå·¥å¤æŸ¥ï¼Ÿ\n\n"
                                    f"ã€æ£€æµ‹æ‘˜è¦å¦‚ä¸‹ã€‘ï¼š\n{summarized_text}"
                        },
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{heatmap_b64}"}
                        },
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{marked_b64}"}
                        }
                    ]
                }
            ]
        }
        try:
            response = requests.post(
                f"{base_url}/chat/completions",
                headers=headers,
                json=payload,
                proxies=proxies,
                timeout=120
            )
            response.raise_for_status()
            summary = response.json()["choices"][0]["message"]["content"]
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(summary)
            print(f"âœ… ç¬¬{page}é¡µç”ŸæˆæˆåŠŸï¼š{output_path}")
        except Exception as e:
            print(f"âŒ ç¬¬{page}é¡µç”Ÿæˆå¤±è´¥ï¼š", e)
        page += 1

# ==== æ‰§è¡Œæ‰¹é‡å¤„ç† ====
if __name__ == "__main__":
    process_batch_reports(report_dir, file_prefix, top_k=10)
